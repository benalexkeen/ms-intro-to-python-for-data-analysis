{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis in Python II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 - Visualising Data\n",
    "\n",
    "Let's start again by importing the modules we'll be using in this section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line Graphs\n",
    "\n",
    "Plot the lines with the points given in the following two arrays, with `X` on the X axis and `Y` on the Y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [1, 2, 3, 4, 5]\n",
    "Y = [10, 20, -5, 12, 24]\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following values are the goals scored by the top 5 Premier League teams between 2011 and 2016, plot these all on the same graph. \n",
    "\n",
    "Make sure you have the legend on the graph and label the X and Y axes.  \n",
    "Also have your graph start from 0 on the Y axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "years = [2011, 2012, 2013, 2014, 2015, 2016]\n",
    "arsenal = [72, 74, 72, 68, 71, 65]\n",
    "chelsea = [69, 65, 75, 71, 73, 59]\n",
    "liverpool = [59, 47, 71, 101, 52, 63]\n",
    "man_city = [60, 93, 66, 102, 83, 71]\n",
    "man_utd = [78, 89, 86, 64, 62, 49]\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the graph for:\n",
    "\n",
    "$ y = \\dfrac{1}{x} $\n",
    "\n",
    "For x between 0.5 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the same graph, draw the lines for\n",
    "\n",
    "$ y = x^2 $  \n",
    "and  \n",
    "$ y = x^4 $\n",
    "\n",
    "for x between -3 and 3.\n",
    "\n",
    "Also plot markers for the individual points where X is an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the same graph draw the lines for\n",
    "\n",
    "$ y = 3 + \\sqrt{6x - x^2 -8} $  \n",
    "and  \n",
    "$ y = 3 - \\sqrt{6x - x^2 -8} $  \n",
    "\n",
    "between 2 < x < 4\n",
    "\n",
    "Draw the first line as a solid green line ('-') and the second line as a dot-dashed red line ('-.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter Plots\n",
    "\n",
    "#### Litter Data Set\n",
    "\n",
    "The file `data/litters.csv` has a number of litters of mice, with the pups' body and brain weights.  \n",
    "\n",
    "Plot a scatter plot of litter size against body weight in grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "litters = pd.read_csv('data/litters.csv')\n",
    "\n",
    "litters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Boxplot\n",
    "\n",
    "Load the iris dataset into a DataFrame as shown in the slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "iris_df['species'] = iris['target']\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now draw 3 boxplots for species 0 (Iris setosa), 1 (Iris versicolor), or 2 (Iris virginica) against `petal length (cm)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UK Driver Deaths Data Set\n",
    "\n",
    "The file UK Driver Deaths contains the number of drivers that died in the UK for each month between 1969 and 1984 inclusive.  \n",
    "\n",
    "Draw a histogram showing the distribution of deaths per month with bins between 1000 and 3000 of width 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deaths = pd.read_csv('data/uk_driver_deaths.csv')\n",
    "\n",
    "deaths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bar Charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a bar chart of the different types of energy fuel against their output in Gigawatt-hours (GWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "energy_types = ['Nuclear', 'Hydro', 'Gas', 'Oil', 'Coal', 'Biofuel']\n",
    "energy = [5, 6, 15, 22, 24, 8]\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot each type of medals against their respective country for the medals they won at the 2012 Olympic Games, pick colours of bars to match the medal colour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "medals_2012 = pd.DataFrame(\n",
    "    {\n",
    "        'gold': [46, 27, 26, 19, 17],\n",
    "        'silver': [37, 23, 18, 18, 10],\n",
    "        'bronze': [38, 17, 26, 19, 15]\n",
    "    }, index = ['USA', 'GB', 'China', 'Russia', 'Germany']\n",
    ")\n",
    "\n",
    "medals_2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 - Data Aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Student's Sleep Data Set\n",
    "\n",
    "The data set below shows 10 students, and their response to two soporific (sleep-inducing) drugs, compared to a control period.  \n",
    "\n",
    "The increase in sleep is given by the variable 'extra'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sleep = pd.DataFrame({\n",
    "    'extra': [0.7, -1.6, -0.2, -1.2, -0.1, 3.4, 3.7, 0.8, 0, 2, 1.9, 0.8, 1.1, 0.1, -0.1, 4.4, 5.5, 1.6, 4.6, 3.4],\n",
    "    'group': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
    "    'ID': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using groupby, find the means of `extra` for `group` 1 and 2, which of the 2 is the more effective drug on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also using groupby, what was the total effect (sum of `extra` sleep) of the soporific drugs for each of the students (`ID`). Which ID was the most susceptible to both drugs in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Product Sales Data Set (Mocked)\n",
    "\n",
    "The data set below describes sales of products from an online retailer. Run the cell below to see some of the sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell to create mocked data set\n",
    "np.random.seed(50)\n",
    "#Â 20 products, 200 transactions, 7 countries\n",
    "prices = {x: np.random.randint(5, 20) for x in np.arange(1, 20)}\n",
    "sales_df = pd.DataFrame({\n",
    "    'Quantity': np.random.randint(1, 5, 200),\n",
    "    'Product_Id': np.random.randint(1, 20, 200),\n",
    "    'Country': np.random.choice(['UK', 'USA', 'France', 'Australia', 'Norway', 'Rep. Ireland', 'Netherlands'], 200)\n",
    "})\n",
    "sales_df['Price'] = sales_df['Product_Id'].map(lambda x: prices[x])\n",
    "sales_df['Revenue'] = sales_df['Price'] * sales_df['Quantity']\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which country brings in the most revenue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which country had the most individual transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which country bought the most items of stock?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which country bought the highest quantity of `Product_Id` 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nobel Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Nobel Foundation would like some information on a data set they have provided you with, it is an Excel document with two sheets named `nobel_prizes` and `population` respectively. \n",
    "\n",
    "This file is in the data directory as `\"data/nobel_prizes.xlsx\"`\n",
    "\n",
    "Read in the two Excel sheets into 2 separate Data Frames\n",
    "\n",
    "_Hint:_ http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nobel = pd.read_excel('data/nobel_prizes.xlsx', sheetname='nobel_prizes')\n",
    "population = # Fill this in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They would first like to know what proportion of winners were female and which category has the most female winners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which country do the most Literature Nobel Prize winners come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many Nobel Prize Winners have the first name \"Robert\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to replace some of the values in the `\"Birth Country\"` column in our `nobel` Data Frame.\n",
    "\n",
    "One of the Nobel Prize winners is listed as coming from French overseas territory `\"Guadeloupe Island\"`. Replace this value with `\"France\"`.\n",
    "\n",
    "Trinidad and Tobago is listed as `\"Trinidad\"`, replace this value with `\"Trinidad and Tobago\"`.\n",
    "\n",
    "`\"Northern Ireland\"` is listed Separately to United Kingdom, replace this value with `\"United Kingdom\"`.\n",
    "\n",
    "There was also a winner from Taiwan, but there is no population entry for Taiwan, so we will have to (perhaps controversially) assign Taiwan to China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# nobel['Birth Country'] = nobel['Birth Country'].replace(\n",
    "#     ['Guadeloupe Island', 'Trinidad', 'Northern Ireland', 'Scotland', 'Taiwan'],\n",
    "#     ['France', 'Trinidad and Tobago', 'United Kingdom', 'United Kingdom', 'China']\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Nobel Foundation would like to know the 5 countries with the most prize winners per capita that were born in that country, use your 2 data frames to calculate this.\n",
    "\n",
    "_Hint: http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.merge.html_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 - Time Series Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the strings in the following Data Frame to datetimes using 3 separate functions. \n",
    "\n",
    "When you've completed, you should see that all the columns in the dataframe are the same.\n",
    "\n",
    "_Hint: Remember you can use http://www.strftime.org for information on date parsing codes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "import datetime\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'a': ['2015-01-04 15:03:00', '2016-12-30 18:18:12', '2017-02-23 09:13:04'],\n",
    "    'b': ['15:03:00, 4 January 2015', '18:18:12, 30 December 2016', '09:13:04, 23 February 2017'],\n",
    "    'c': ['01/04/2015 15:03:00', '12/30/2016 18:18:12', '02/23/2017 09:13:04']\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here, make sure all columns in the data frame read the same when you're code is complete\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reading in our csv `'distances.csv'`\n",
    "\n",
    "This is a csv that contains mocked data for the sum of distances covered by 100 people in each minute of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/distances.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the function we created in the last section to parse column `a` to parse our `datetime` column here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot a line graph of distance against time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make out a trend but it's hardly pretty, this data is for every minute of the day.\n",
    "\n",
    "Make the datetime column your Data Frame's index, then resample to an hourly granularity, summing up each of the values within each hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, again plot a line graph distance against time and see how this compares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first graph there would have been no way of noticing the peaks at 09:00 - 10:00 or 18:00 - 19:00, but in our resampled graph we can see the same general trends but peaks and troughs are much easier to discern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timezones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By convention, the Z in the following string denotes that this time is UTC.\n",
    "\n",
    "Take this string parse it to a datetime, then `localize()` it so that it has a UTC timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utc_dt_str = '2017-05-03T14:15:00Z'\n",
    "\n",
    "import pytz\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Olson timezone `'America/Los_Angeles'`, `normalize()` this date so that it is now in Los Angeles time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now write a function `convert_to_la_time()` to do the above and use the `map()` function to convert all the times in the Series below to Los Angeles time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datetimes = pd.Series(['2017-05-03T14:00:00Z', '2017-05-03T14:15:00Z', \n",
    "                       '2017-05-03T14:30:00Z', '2017-05-03T14:45:00Z'])\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4 - K-nearest Neighbors Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will be using a data set with lots of features about breast cancer to try and predict whether a tumour is benign or malignant.\n",
    "\n",
    "We will be using K-nearest Neighbors to classify unseen observations into benign (0) or malignant (1).\n",
    "\n",
    "Let's start by loading the data and taking a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# run this cell\n",
    "\n",
    "breast_cancer_df = pd.read_csv('data/breast_cancer.csv')\n",
    "breast_cancer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 30 feature columns that describe our tumours, including \"mean radius\", \"mean texture\", \"mean perimeter\"...\n",
    "\n",
    "There is a single column (you need to scroll right in the output of the cell above) named `'malignancy'` and this tells us whether a tumour is benign (0) or malignant (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by splitting our data out into test data and training data.\n",
    "\n",
    "Create a variable `X` that is a Data Frame with all the columns except `\"malignancy\"`.\n",
    "\n",
    "Create a variable `y` that is the series of the column `\"malignancy\"`.\n",
    "\n",
    "Then we split `X` and `y` into test and training data, give the output data the names: \n",
    "* `X_train` - This data will be the features you use to train the models.\n",
    "* `X_test` - This data will be the features that act as unseen data to make predictions against.\n",
    "* `y_train` - This data will be the labels for training the model.\n",
    "* `y_test` - This will be the unseen labels you score your predictions against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variables X and y here\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data here into X_train, X_test, y_train and y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the scale of some of our columns are over 1000 and some of our columns have a scale of less than 1. Therefore some features would skew the model disproportionately than others.\n",
    "\n",
    "Therefore we must scale our data.\n",
    "\n",
    "Here we will use the `MinMaxScaler()` to scale our data. For more details on this, see my [blog post](http://benalexkeen.com/feature-scaling-with-scikit-learn/) or the [official docs](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html).\n",
    "\n",
    "We first fit the scaler to our training data, then we use it to scale our training data. We will later also use it to scale our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Returns a 2D array\n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "# Convert back to a DataFrame\n",
    "X_train = pd.DataFrame(scaled_X_train, columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a K Neighbors Classifier model object that uses the 6 nearest neighbors.\n",
    "\n",
    "Fit this model to your training data (`X_train` and `y_train`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=6)\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the scaler to transform your `X_test` data as we did for the `X_train` data above (only transform, not fit, we only ever fit on our training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use your model to predict the labels from the scaled `X_test` data and store these predictions in the variable `y_predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `accuracy_score` to compare how your prediction performed against the unseen `y_test` labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How accurate was the prediction from your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5 - Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we wil be using some factors indicative of economical wellbeing to predict the price of a Big Mac.\n",
    "\n",
    "We'll start be reading in the data. This data has the price of a Big Mac in US dollars, the GDP per capita in dollars, the life expectancy in years and the unemployment rate as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/bigmac.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a scatter plot of gdp per capita against the price of a big mac to see if there is any correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the variables `X` and `y`. \n",
    "\n",
    "`X` will be a Data Frame of the columns `'gdp_per_capita'`, `'life_expectancy'` and `'unemployment'`.  \n",
    "`y` will be the `big_mac_price` Series from our Data Frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "\n",
    "\n",
    "# random_state defined for repeatability\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a linear regression model and fit it on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `score()` method from our model and our `X_test` and `y_test` test data sets, calculate the $ R^2 $ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This $R^2$ value may seem small but remember a 0.5 $ R^2 $ value corresponds to a correlation of over 70%. \n",
    "\n",
    "Also note that there are far more factors that might affect a Big Mac's price, including obesity rates, taxation on fast food, shipping costs etc. etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the coefficients from the model's `coef_` attribute and the intercept from the model's `intercept_` attribute. \n",
    "\n",
    "Use these to construct an equation in the form:\n",
    "\n",
    "$ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 X_3 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `predict()` method of our linear regression model to predict a new `y` value as follows:\n",
    "\n",
    "`regression_model.predict([[x1, x2, x3]])`\n",
    "\n",
    "It is a list of lists as you could provide multiple lists of `[x1, x2, x3]` to get multiple `y` predictions.\n",
    "\n",
    "McDonald's currently has no restaurants in Macedonia. \n",
    "\n",
    "It has a GDP per capita of \\$14,500, a life expectancy of 76.02 and an unemployment rate of 23.1%, what would we expect to pay for a Big Mac in Macedonia in \\$ if it was to be released?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6 - Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A telephone company has decided to erect 7 more telephone masts in Cornwall, UK.\n",
    "\n",
    "It has obtained some GPS data from mobile of people that visited Cornwall on holiday.\n",
    "\n",
    "Start by reading in the data for these phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "df = pd.read_csv('data/cornwall_phones.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a K means clustering model with 7 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model now has 7 centroids (cluster centers), use the `cluster_centers_` method of the model to determine where these are.\n",
    "\n",
    "Store the centroids in a variable named `centroids`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cells below to create a map with your centroids plotted on. \n",
    "\n",
    "This may take a minute or two. \n",
    "\n",
    "\n",
    "Explore the map and see where the best positions for new masts to deal with the influx of summer tourists are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ask your instructor for the access token\n",
    "mapbox_access_token = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import Data, Scattermapbox, Layout, Marker\n",
    "\n",
    "data = Data([\n",
    "    Scattermapbox(\n",
    "        lat=[x[0] for x in centroids],\n",
    "        lon=[x[1] for x in centroids],\n",
    "        mode='markers',\n",
    "        marker=Marker(\n",
    "            size=14\n",
    "        ),\n",
    "        text=['Centroid'],\n",
    "    )\n",
    "])\n",
    "\n",
    "layout = Layout(\n",
    "    autosize=True,\n",
    "    hovermode='closest',\n",
    "    mapbox=dict(\n",
    "        accesstoken=mapbox_access_token,\n",
    "        bearing=0,\n",
    "        center=dict(\n",
    "            lat=50.2,\n",
    "            lon=-5\n",
    "        ),\n",
    "        pitch=0,\n",
    "        zoom=7\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='Centroid plot')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
